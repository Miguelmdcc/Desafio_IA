{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando o dataset com temporal_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.forecasting.model_selection import temporal_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seller_id = 100000060\n",
    "# time_serie = model_df[model_df['Seller ID'] == seller_id]\n",
    "# time_serie.drop(columns=['Seller ID','Day of Week','Last Week','Last Month'],inplace=True)\n",
    "# time_serie['Change'] = time_serie['Change'].astype('Int64')\n",
    "# time_serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag de um dia na nossa time serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_serie.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = time_serie.pop('Transactioned')\n",
    "# y = pd.DataFrame(data=target,columns=['Transactioned'])\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_serie = time_serie.shift(1)\n",
    "# time_serie.drop(pd.to_datetime('2024-01-30'), inplace=True)\n",
    "# time_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_to_pred = pd.to_datetime('2024-11-04')\n",
    "# time_serie = time_serie[time_serie.index < date_to_pred]\n",
    "# y = y[y.index<date_to_pred]\n",
    "# y.drop(pd.to_datetime('2024-01-30'), inplace=True)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_test, X_train, X_test = temporal_train_test_split(y,time_serie,test_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.forecasting.base import ForecastingHorizon\n",
    "# import numpy as np\n",
    "\n",
    "# fh = ForecastingHorizon(np.arange(1,len(y_test)+2),is_relative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# # Calculando scale_pos_weight\n",
    "# n_pos = len(y_train[y_train['Transactioned'] == 1])\n",
    "# n_neg = len(y_train[y_train['Transactioned'] == 0])\n",
    "# scale_pos_weight = n_neg / n_pos\n",
    "\n",
    "# xgb_model = XGBRegressor(\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.1,\n",
    "#     max_depth=5,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     random_state=42,\n",
    "#     scale_pos_weight=scale_pos_weight\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.forecasting.compose import make_reduction\n",
    "\n",
    "# forecaster = make_reduction(xgb_model, window_length=12, strategy=\"recursive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecaster.fit(y=y_train,X=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = forecaster.predict(fh=fh,X=X_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.utils.plotting import plot_series\n",
    "# plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Análise de erros\n",
    "# errors = abs(y_test['Transactioned'].values - y_pred.values)\n",
    "# print(\"Erro Médio Absoluto (MAE):\", errors.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterando em sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from xgboost import XGBRegressor\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.utils.plotting import plot_series\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.forecasting.model_selection import SlidingWindowSplitter,ForecastingGridSearchCV, ForecastingOptunaSearchCV\n",
    "from sktime.split import SingleWindowSplitter\n",
    "from tqdm import tqdm\n",
    "from sktime.performance_metrics.forecasting import MeanAbsoluteError\n",
    "from optuna import Trial\n",
    "import optuna\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/workspace/Desafio Grão Direto IA/Data/model_df.xlsx'\n",
    "model_df = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos com hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_seller_gs(seller_id):\n",
    "#     #print(f\"Processando Seller ID: {seller_id}\")\n",
    "    \n",
    "#     # Filtrar os dados para o Seller ID atual\n",
    "#     time_serie = model_df[model_df['Seller ID'] == seller_id]\n",
    "#     time_serie = time_serie.drop(columns=['Seller ID','Day of Week'])\n",
    "    \n",
    "#     # Preparação da série temporal\n",
    "#     time_serie.set_index('Date', inplace=True)\n",
    "#     target = time_serie.pop('Transactioned')\n",
    "#     y = pd.DataFrame(data=target, columns=['Transactioned'])\n",
    "#     time_serie = time_serie.shift(1)\n",
    "    \n",
    "#     # Remover valores fora do intervalo de datas desejado\n",
    "#     date_to_pred = pd.to_datetime('2024-11-04')\n",
    "#     first_date = pd.to_datetime('2024-01-30')\n",
    "#     mask = (time_serie.index > first_date) & (time_serie.index < date_to_pred)\n",
    "#     time_serie = time_serie.loc[mask]\n",
    "#     y = y.loc[mask]\n",
    "\n",
    "#     # Dividir os dados em treino e teste\n",
    "#     y_train, y_test, X_train, X_test = temporal_train_test_split(y, time_serie, test_size=2)\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "#     X_train = pd.DataFrame(data=X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "#     X_test = pd.DataFrame(data=X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "    \n",
    "#     # Configuração do Forecasting Horizon\n",
    "#     fh = ForecastingHorizon([3], is_relative=True)\n",
    "    \n",
    "#     # Calculando scale_pos_weight\n",
    "#     n_pos = len(y_train[y_train['Transactioned'] == 1])\n",
    "#     n_neg = len(y_train[y_train['Transactioned'] == 0])\n",
    "#     scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1\n",
    "    \n",
    "#     # Configuração do modelo e busca\n",
    "#     param_grid = {\n",
    "#         'n_estimators': [100, 500],\n",
    "#         'learning_rate': [0.01, 0.1],\n",
    "#         'max_depth': [3, 6],\n",
    "#         'subsample': [0.1, 0.3],\n",
    "#         'colsample_bytree': [0.6, 0.8]\n",
    "#     }\n",
    "\n",
    "#     xgb_model = XGBRegressor(\n",
    "#         objective='reg:squarederror',\n",
    "#         random_state=42,\n",
    "#         scale_pos_weight=scale_pos_weight\n",
    "#     )\n",
    "    \n",
    "#     # Criar o modelo\n",
    "#     forecaster = make_reduction(xgb_model, window_length=12, strategy=\"recursive\")\n",
    "\n",
    "#     cv = SingleWindowSplitter(window_length=len(y)-2,fh=2)\n",
    "\n",
    "#     # Criar o ForecastingGridSearchCV\n",
    "#     grid_search = ForecastingGridSearchCV(\n",
    "#         forecaster=forecaster,\n",
    "#         param_grid=param_grid,\n",
    "#         cv=cv,\n",
    "#         scoring=MeanAbsoluteError()\n",
    "#     )\n",
    "\n",
    "#     #Treinando modelo\n",
    "#     grid_search.fit(y=y_train, X=X_train)\n",
    "    \n",
    "#     # Previsão\n",
    "#     y_pred = grid_search.predict(fh=fh, X=X_test)\n",
    "#     # y_pred_04 = y_pred.loc['2024-11-04']\n",
    "\n",
    "#     # # Análise de erros\n",
    "#     # errors = abs(y_test['Transactioned'].values - y_pred.values)\n",
    "#     # mae = errors.mean()\n",
    "#     # print(f\"Erro Médio Absoluto (MAE) para Seller ID {seller_id}: {mae}\")\n",
    "    \n",
    "#     # # Plot das séries\n",
    "#     # plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "#     # plt.title(f\"Previsão para Seller ID: {seller_id}\")\n",
    "#     # plt.show()\n",
    "    \n",
    "#     # Armazenar os resultados\n",
    "\n",
    "#     gs = grid_search.best_params_\n",
    "\n",
    "#     seller = {\n",
    "#         \"Seller ID\": seller_id,\n",
    "#         \"Date\": y_pred.index.values[0],  # Extract the single date value\n",
    "#         \"Score\": y_pred['Transactioned'].values[0],  # Extract the single score value\n",
    "#         \"colsample_bytree\": gs['colsample_bytree'],\n",
    "#         \"learning_rate\": gs['learning_rate'],\n",
    "#         \"max_depth\": gs['max_depth'],\n",
    "#         \"n_estimators\": gs['n_estimators'],\n",
    "#         \"subsample\": gs['subsample']\n",
    "#     }\n",
    "\n",
    "#     return seller\n",
    "\n",
    "# # Lista de Seller IDs\n",
    "# seller_ids = model_df['Seller ID'].unique()\n",
    "\n",
    "# # Resultados para armazenar os erros por vendedor\n",
    "# results = []\n",
    "\n",
    "# # Criar a barra de progresso manualmente\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     # Usar tqdm para iterar nos vendedores enquanto processa\n",
    "#     for result in tqdm(executor.map(process_seller_gs, seller_ids), total=10, desc=\"Processando Sellers\"):\n",
    "#         results.append(result)\n",
    "\n",
    "# # Criar DataFrame com os resultados\n",
    "# results_df = pd.DataFrame(results)\n",
    "# # results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72 minutos e 33,5 segundos - todos os Sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, module='sktime')\n",
    "# def process_seller_optuna(seller_id):\n",
    "#     #print(f\"Processando Seller ID: {seller_id}\")\n",
    "    \n",
    "#     # Filtrar os dados para o Seller ID atual\n",
    "#     time_serie = model_df[model_df['Seller ID'] == seller_id]\n",
    "#     time_serie = time_serie.drop(columns=['Seller ID','Day of Week'])\n",
    "    \n",
    "#     # Preparação da série temporal\n",
    "#     time_serie.set_index('Date', inplace=True)\n",
    "#     target = time_serie.pop('Transactioned')\n",
    "#     y = pd.DataFrame(data=target, columns=['Transactioned'])\n",
    "#     time_serie = time_serie.shift(1)\n",
    "    \n",
    "#     # Remover valores fora do intervalo de datas desejado\n",
    "#     date_to_pred = pd.to_datetime('2024-11-05')\n",
    "#     first_date = pd.to_datetime('2024-01-30')\n",
    "#     mask = (time_serie.index > first_date) & (time_serie.index < date_to_pred)\n",
    "#     time_serie = time_serie.loc[mask]\n",
    "#     y = y.loc[mask]\n",
    "\n",
    "#     # Dividir os dados em treino e teste\n",
    "#     y_train, y_test, X_train, X_test = temporal_train_test_split(y, time_serie, test_size=1)\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "#     X_train = pd.DataFrame(data=X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "#     X_test = pd.DataFrame(data=X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "    \n",
    "#     # Configuração do Forecasting Horizon\n",
    "#     fh = ForecastingHorizon([1], is_relative=True)\n",
    "    \n",
    "#     # Calculando scale_pos_weight\n",
    "#     n_pos = len(y_train[y_train['Transactioned'] == 1])\n",
    "#     n_neg = len(y_train[y_train['Transactioned'] == 0])\n",
    "#     scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1\n",
    "    \n",
    "#     # Configuração do modelo e busca\n",
    "#     param_grid = {\n",
    "#         'n_estimators': optuna.distributions.IntDistribution(100, 1000),\n",
    "#         'learning_rate': optuna.distributions.FloatDistribution(0.01, 0.8),\n",
    "#         'max_depth': optuna.distributions.IntDistribution(2, 10),\n",
    "#         'subsample': optuna.distributions.FloatDistribution(0.1, 0.8),\n",
    "#         'colsample_bytree': optuna.distributions.FloatDistribution(0.2, 0.8)\n",
    "#     }\n",
    "\n",
    "#     xgb_model = XGBRegressor(\n",
    "#         scale_pos_weight=scale_pos_weight\n",
    "#     )\n",
    "    \n",
    "#     # Criar o modelo\n",
    "#     forecaster = make_reduction(xgb_model, window_length=12, strategy=\"recursive\")\n",
    "\n",
    "#     cv = SingleWindowSplitter(window_length=len(y_train),fh=fh)\n",
    "\n",
    "#     # Criar o ForecastingGridSearchCV\n",
    "#     optuna_search = ForecastingOptunaSearchCV(\n",
    "#         forecaster=forecaster,\n",
    "#         param_grid=param_grid,\n",
    "#         cv=cv,\n",
    "#         n_evals=10,\n",
    "#     )\n",
    "\n",
    "    \n",
    "#     #Treinando modelo\n",
    "#     optuna_search.fit(y=y_train,X=X_train)\n",
    "\n",
    "#     # Previsão\n",
    "#     y_pred = optuna_search.predict(fh=fh, X=X_test)\n",
    "\n",
    "#     # y_pred_04 = y_pred.loc['2024-11-04']\n",
    "\n",
    "#     # # Análise de erros\n",
    "#     # errors = abs(y_test['Transactioned'].values - y_pred.values)\n",
    "#     # mae = errors.mean()\n",
    "#     # print(f\"Erro Médio Absoluto (MAE) para Seller ID {seller_id}: {mae}\")\n",
    "    \n",
    "#     # # Plot das séries\n",
    "#     # plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "#     # plt.title(f\"Previsão para Seller ID: {seller_id}\")\n",
    "#     # plt.show()\n",
    "    \n",
    "#     # Armazenar os resultados\n",
    "\n",
    "#     ops = optuna_search.best_params_\n",
    "#     # print(gs)\n",
    "\n",
    "#     seller = {\n",
    "#         \"Seller ID\": seller_id,\n",
    "#         \"Date\": y_pred.index.values[0],  # Extract the single date value\n",
    "#         \"Score\": y_pred['Transactioned'].values[0],  # Extract the single score value\n",
    "#         \"colsample_bytree\": ops['colsample_bytree'],\n",
    "#         \"learning_rate\": ops['learning_rate'],\n",
    "#         \"max_depth\": ops['max_depth'],\n",
    "#         \"n_estimators\": ops['n_estimators'],\n",
    "#         \"subsample\": ops['subsample']\n",
    "#     }\n",
    "\n",
    "#     return seller\n",
    "\n",
    "\n",
    "# # Lista de Seller IDs\n",
    "# seller_ids = model_df['Seller ID'].unique()\n",
    "\n",
    "# # Resultados para armazenar os erros por vendedor\n",
    "# results = []\n",
    "\n",
    "# for seller_id in tqdm(seller_ids, total=len(seller_ids), desc=\"Processando Sellers\"):\n",
    "#     result = process_seller_optuna(seller_id)\n",
    "#     results.append(result)\n",
    "\n",
    "# # Criar DataFrame com os resultados\n",
    "# results_df = pd.DataFrame(results)\n",
    "# # results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73 minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seller(seller_id):\n",
    "    #print(f\"Processando Seller ID: {seller_id}\")\n",
    "    \n",
    "    # Filtrar os dados para o Seller ID atual\n",
    "    time_serie = model_df[model_df['Seller ID'] == seller_id]\n",
    "    time_serie = time_serie.drop(columns=['Seller ID','Day of Week'])\n",
    "    \n",
    "    # Preparação da série temporal\n",
    "    time_serie.set_index('Date', inplace=True)\n",
    "    target = time_serie.pop('Transactioned')\n",
    "    y = pd.DataFrame(data=target, columns=['Transactioned'])\n",
    "    time_serie = time_serie.shift(1)\n",
    "    \n",
    "    # Remover valores fora do intervalo de datas desejado\n",
    "    date_to_pred = pd.to_datetime('2024-11-05')\n",
    "    first_date = pd.to_datetime('2024-01-30')\n",
    "    mask = (time_serie.index > first_date) & (time_serie.index < date_to_pred)\n",
    "    time_serie = time_serie.loc[mask]\n",
    "    y = y.loc[mask]\n",
    "\n",
    "    # Dividir os dados em treino e teste\n",
    "    y_train, y_test, X_train, X_test = temporal_train_test_split(y, time_serie, test_size=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_train = pd.DataFrame(data=X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "    X_test = pd.DataFrame(data=X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "    \n",
    "    # Configuração do Forecasting Horizon\n",
    "    fh = ForecastingHorizon([1], is_relative=True)\n",
    "    \n",
    "    # Calculando scale_pos_weight\n",
    "    n_pos = len(y_train[y_train['Transactioned'] == 1])\n",
    "    n_neg = len(y_train[y_train['Transactioned'] == 0])\n",
    "    scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1\n",
    "\n",
    "    xgb_model = XGBRegressor(\n",
    "        # max_depth=6,        # Moderate tree depth to prevent overfitting\n",
    "        # gamma=5,            # Restricts splits to meaningful ones\n",
    "        # subsample=0.8,      # Uses a subset of data for diversity\n",
    "        # learning_rate=0.1,  # Smaller learning steps for stability\n",
    "        # n_estimators=100,   # Number of trees\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "    )\n",
    "    \n",
    "    # Criar o modelo\n",
    "    forecaster = make_reduction(xgb_model, window_length=12, strategy=\"recursive\")\n",
    "\n",
    "    #Treinando modelo\n",
    "    forecaster.fit(y=y_train, X=X_train)\n",
    "    \n",
    "    # Previsão\n",
    "    y_pred = forecaster.predict(fh=fh, X=X_test)\n",
    "    # y_pred_04 = y_pred.loc['2024-11-04']\n",
    "\n",
    "    # Análise de erros\n",
    "    errors = abs(y_test['Transactioned'].values - y_pred.values)\n",
    "    mae = errors.mean()\n",
    "    print(f\"Erro Médio Absoluto (MAE) para Seller ID {seller_id}: {mae}\")\n",
    "    \n",
    "    # # Plot das séries\n",
    "    # plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "    # plt.title(f\"Previsão para Seller ID: {seller_id}\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    return{\n",
    "        \"Seller ID\": seller_id,\n",
    "        \"Date\": y_pred.index.values[0],  # Extract the single date value\n",
    "        \"Score\": y_pred['Transactioned'].values[0],  # Extract the single score value\n",
    "        \"MAE\": mae\n",
    "    }\n",
    "\n",
    "# Lista de Seller IDs\n",
    "seller_ids = model_df['Seller ID'].unique()\n",
    "\n",
    "# Resultados para armazenar os erros por vendedor\n",
    "results = []\n",
    "\n",
    "for seller_id in tqdm(seller_ids, total=len(seller_ids), desc=\"Processando Sellers\"):\n",
    "    result = process_seller(seller_id)\n",
    "    results.append(result)\n",
    "\n",
    "# Criar DataFrame com os resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = results_df['Score'].mean()\n",
    "media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_that_made_transaction_on_target_date_04 = [\n",
    "    100000060,\n",
    "    100000141,\n",
    "    100000192,\n",
    "    100000310,\n",
    "    100000348,\n",
    "    100001098,\n",
    "    100001362,\n",
    "    100001525,\n",
    "    100002035,\n",
    "    100002271,\n",
    "    100002332,\n",
    "    100002339,\n",
    "    100002402,\n",
    "    100002426,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_that_made_transaction_on_target_date_05 = [\n",
    "    100000180,\n",
    "    100000037,\n",
    "    100001254,\n",
    "    10000088,\n",
    "    100001203,\n",
    "    100001098,\n",
    "    100001599,\n",
    "    100001885,\n",
    "    100000608,\n",
    "    100000151,\n",
    "    100000638,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_200_predictions = results_df.sort_values(\n",
    "    ascending=False, by=\"Score\"\n",
    ").head(200)\n",
    "\n",
    "\n",
    "first_200_predictions = first_200_predictions[\n",
    "    first_200_predictions[\"Seller ID\"].isin(users_that_made_transaction_on_target_date_04)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_200_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_200_predictions.to_excel('C:/workspace/Desafio Grão Direto IA/Data/200_preds_opscv.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coisas a fazer\n",
    "- PCA |\n",
    "- GRIDSEARCH\n",
    "- OPTUNASEARCH\n",
    "- CONCURRENT FUTURES V\n",
    "- Hierarchical Clustering |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomar cuidado com features categoricas, até mesmo transformadas em int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# model_cl = model_df.drop(columns=['Seller ID', 'Transactioned'])\n",
    "# model_cl = model_cl.set_index('Date')\n",
    "# scaler = StandardScaler()\n",
    "# model_clp = scaler.fit_transform(model_cl)\n",
    "# model_clp = pd.DataFrame(model_clp, columns=model_cl.columns)\n",
    "# model_clp = model_clp.transpose()\n",
    "\n",
    "# linked = linkage(model_clp, method='ward', metric='euclidean')\n",
    "\n",
    "# df_linked = pd.DataFrame(linked, columns=['c1', 'c2', 'distance', 'size'])\n",
    "# df_linked[['c1', 'c2', 'size']] = df_linked[['c1', 'c2', 'size']].astype('Int64')\n",
    "\n",
    "# plt.figure(figsize=(15,5))\n",
    "\n",
    "# dendrogram(linked, orientation='top', labels=model_clp.index, distance_sort='descending', show_leaf_counts=True)\n",
    "# plt.xlabel('Features')\n",
    "# plt.ylabel('Wards')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estudoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
